*April 26, 2021*
***
# Pokédex Kanto

<a href="https://portfolio.atitkharel.com.np/view/3" target="_blank"><img src="https://img.shields.io/badge/Live%20Demo-WebXR-E1101A" alt="Pokedex Kanto WebXR"></a>
<a href="https://lens.snapchat.com/3cff8cef4cc94839863f7f7dd90bdae6" target="_blank"><img src="https://img.shields.io/badge/Snapchat-Lens-FFFC00" alt="Pokedex Kanto"></a>

</br>
<img src="https://media1.giphy.com/media/OJPPkGKXbH3Q0YXmvs/giphy.gif?cid=790b76112d2874212823f347fc4fb250a85b34c29e923e0b&rid=giphy.gif&ct=g" alt="NFT Viewer VR" height="500"/>

## Overview

The **Pokédex Kanto AR Experience** brings the beloved world of Pokémon into Augmented Reality (AR) using Machine Learning (ML). This interactive AR lens allows users to recognize Pokémon from the Kanto region, providing instant information about the Pokémon they scan. The project combines the power of AR, ML, and a 3d model of a Pokédex to create an engaging experience for Pokémon enthusiasts.

### Built With

![Snap Lens Studio](https://img.shields.io/badge/Snap%20Lens%20Studio-FFFC00?style=for-the-badge&logo=snapchat&logoColor=black)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)

## Inspiration

The idea first came to me when Lens Studio launched its SnapML feature in Lens Studio. I wanted to explore the possibilities of integrating ML models into AR experiences and as a Pokémon fan, I decided to create a Pokédex AR experience that would allow users to scan and identify Pokémon in the real world.

## Project Highlights

The **Pokédex Kanto** project exemplifies how augmented reality and machine learning can be merged to create interactive experiences. It can recognize and display detailed Pokémon stats like HP, Attack, Defense, Speed and more. The project's key features include:

- **Pokémon Recognition**: Recognizes Kanto Pokémon in real-time and displays their information.
- **AR Integration**: Users can experience the lens on Snapchat to view the Pokedex in your hands in AR through hand tracking.
- **Snap Camera Kit**: The experience works on mobile devices using Snapchat's App but can also be accessed on desktops or other platforms through browser using Snap's Camera Kit.
- **Stat Display**: Displays Pokémon stats, abilities, and type information on the screen of the 3D Pokédex model.

## Development Process and How It Works

The ML model used in this project is a custom-trained model using the [Kaggle dataset](https://www.kaggle.com/datasets/thedagger/pokemon-generation-one) of Pokémon images. The model is trained to recognize the **151 Pokémon** from the **Kanto region** and provide relevant information about each Pokémon. The model was trained using TensorFlow and Keras, and converted to an Open Neural Network Exchange ([.ONNX](https://onnx.ai/)) file for use in Lens Studio.

For each Pokémon, key stats such as HP, Attack, Defense, Speed, Special Attack, Special Defense, and Type, along with their low-resolution images, were retrieved from the [Poke API](https://pokeapi.co/) using Python. The retrieved data were stored in a JSON file, which is used to display information about the recognized Pokémon. This approach also supports offline use of the experience.

When users point their camera to a Pokémon and tap on the screen, the ML Model gives the name of the Pokémon recognized and the 3D model of the Pokédex is displayed with the Pokémon's information on its screen. Hand tracking is used to place the Pokédex in the user's hand in AR but users can still view the experience without hand tracking where the Pokédex is placed in the center of the screen.

## Challenges Faced

- **Accurate Pokémon Identification**: Ensuring that the machine learning model accurately recognizes each Pokémon based on subtle differences in appearance like evolved forms or shiny variants was a significant challenge.
- **Optimization**: Displaying Pokémon information in a 3D model with images and text required careful design and optimization, as Lens Studio supports only up to 4MB for the total size of the lens. This necessitated compressing both the images and the ONNX model to fit within the size limit. These optimizations were also crucial for maintaining speed and performance, preventing any lag or delays during interaction.

## Learnings

This project provided valuable insights into the integration of machine learning and augmented reality. I was able to gain a deeper understanding of how ML models are trained for real-time applications, particularly in the context of interactive and visually-driven environments like AR. Moreover, the project underscored the importance of smooth user experiences in AR, from fast recognition to engaging visual displays and an optimized experience for different platforms.

## Future Enhancement

- **Expanded Pokémon Recognition**: In the future, I plan to extend the lens to recognize Pokémon from other regions beyond Kanto, creating a more comprehensive Pokédex.

## Conclusion

The **Pokédex Kanto AR Experience** blends the nostalgia of Pokémon with ML and AR create an engaging, interactive tool for fans. By allowing users to scan and recognize Pokémon in the real world, it opens up a whole new way of interacting with these beloved characters. The project showcases the potential of AR and ML to transform how we engage with our favorite franchises, offering a glimpse into the future of interactive entertainment.
